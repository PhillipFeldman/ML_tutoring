{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a805c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\phill\\anaconda3\\envs\\tf\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e33f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c920da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMGSIZE = (128, 128)\n",
    "CNAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "X_tr, y_tr, X_ts, y_ts = [], [], [], []\n",
    "_path = '.'\n",
    "for label in CNAMES:\n",
    "    path = _path + '/seg_train/seg_train/' + label\n",
    "    for f in sorted([_ for _ in os.listdir(path) if _.lower().endswith('.jpg')]):\n",
    "        X_tr += [cv2.resize(cv2.imread(os.path.join(path,f)), IMGSIZE)]\n",
    "        y_tr += [CNAMES.index(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f88a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGSIZE = (128, 128)\n",
    "CNAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
    "for label in CNAMES:\n",
    "    path = \".\" + '/seg_test/seg_test/' + label\n",
    "    for f in sorted([_ for _ in os.listdir(path) if _.lower().endswith('.jpg')]):\n",
    "        X_ts += [cv2.resize(cv2.imread(os.path.join(path,f)), IMGSIZE)]\n",
    "        y_ts += [CNAMES.index(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14233e1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'i' in function 'cvDestroyWindow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39marray(X_tr[\u001b[38;5;241m0\u001b[39m] ,dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8))\n\u001b[0;32m      2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1261: error: (-27:Null pointer) NULL window: 'i' in function 'cvDestroyWindow'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('i',np.array(X_tr[0] ,dtype=np.uint8))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ce68c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "number_of_color_channels=X_tr[0].shape[2]\n",
    "number_of_color_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f077a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14034, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "X_trnp = np.array(X_tr)\n",
    "y_trnp = np.array(y_tr)\n",
    "X_tsnp = np.array(X_ts)\n",
    "y_tsnp = np.array(y_ts)\n",
    "X_trnp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5facdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trscaled = X_trnp/255\n",
    "X_tsscaled = X_tsnp/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3f21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb51cb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96078431, 0.96862745, 0.96862745],\n",
       "       [0.96078431, 0.96862745, 0.96862745],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97647059, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96470588, 0.97647059, 0.96862745],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.97254902, 0.98431373, 0.97647059],\n",
       "       [0.97254902, 0.98823529, 0.96862745],\n",
       "       [0.97254902, 0.98823529, 0.96862745],\n",
       "       [0.96862745, 0.98431373, 0.96470588],\n",
       "       [0.96470588, 0.98039216, 0.96470588],\n",
       "       [0.95686275, 0.97647059, 0.96862745],\n",
       "       [0.95686275, 0.97647059, 0.96862745],\n",
       "       [0.95686275, 0.97647059, 0.96862745],\n",
       "       [0.95294118, 0.97254902, 0.96470588],\n",
       "       [0.95294118, 0.97254902, 0.96470588],\n",
       "       [0.95294118, 0.97254902, 0.96470588],\n",
       "       [0.96078431, 0.98039216, 0.97254902],\n",
       "       [0.96078431, 0.98039216, 0.97254902],\n",
       "       [0.96078431, 0.98039216, 0.97254902],\n",
       "       [0.96078431, 0.98039216, 0.97254902],\n",
       "       [0.96470588, 0.98431373, 0.97647059],\n",
       "       [0.96470588, 0.98431373, 0.97647059],\n",
       "       [0.96078431, 0.98039216, 0.97254902],\n",
       "       [0.96470588, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96470588, 0.97647059, 0.96862745],\n",
       "       [0.96078431, 0.97254902, 0.96470588],\n",
       "       [0.96862745, 0.97254902, 0.96470588],\n",
       "       [0.97647059, 0.98039216, 0.97254902],\n",
       "       [0.97254902, 0.97647059, 0.96862745],\n",
       "       [0.97254902, 0.97647059, 0.96862745],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.98039216, 0.97254902],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96078431, 0.96862745, 0.96862745],\n",
       "       [0.96078431, 0.96862745, 0.96862745],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97647059, 0.98431373, 0.98431373],\n",
       "       [0.97254902, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97647059, 0.98431373, 0.98431373],\n",
       "       [0.97647059, 0.98431373, 0.98431373],\n",
       "       [0.97254902, 0.98039216, 0.98431373],\n",
       "       [0.97254902, 0.98039216, 0.98431373],\n",
       "       [0.97254902, 0.98039216, 0.98431373],\n",
       "       [0.98039216, 0.97647059, 0.98431373],\n",
       "       [0.97647059, 0.98039216, 0.98431373],\n",
       "       [0.97647059, 0.98431373, 0.98431373],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.97647059, 0.98431373, 0.98431373],\n",
       "       [0.98039216, 0.98823529, 0.98823529],\n",
       "       [0.98431373, 0.98431373, 0.98431373],\n",
       "       [0.98039216, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.98039216, 0.98039216],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96470588, 0.97254902, 0.97254902],\n",
       "       [0.96078431, 0.97647059, 0.97254902],\n",
       "       [0.95686275, 0.97647059, 0.97254902],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.96862745, 0.97647059, 0.97647059],\n",
       "       [0.97254902, 0.97647059, 0.97647059],\n",
       "       [0.97647059, 0.97647059, 0.97647059],\n",
       "       [0.97647059, 0.97647059, 0.97647059],\n",
       "       [0.97647059, 0.97647059, 0.97647059],\n",
       "       [0.98039216, 0.98039216, 0.98039216],\n",
       "       [0.97254902, 0.97254902, 0.97254902],\n",
       "       [0.97254902, 0.97254902, 0.97254902],\n",
       "       [0.96470588, 0.96862745, 0.96862745],\n",
       "       [0.96078431, 0.96862745, 0.96862745]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trscaled[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe322b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e8cee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = np.array(y_tr)\n",
    "y_ts = np.array(y_ts)\n",
    "y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206452da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c71de627",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Our full CNN neural network\n",
    "cnn1 = tf.keras.Sequential()\n",
    "\n",
    "# if necessary keep the image size same padding='same'\n",
    "cnn1.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5),\n",
    "    data_format='channels_last',\n",
    "    name='conv_1', activation='relu'))\n",
    "\n",
    "cnn1.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_1'))  # 12x12 image size\n",
    "\n",
    "# if necessary keep the image size same padding='same'\n",
    "cnn1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5),\n",
    "    name='conv_2', activation='relu'))\n",
    "\n",
    "cnn1.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_2'))  # 4x4 image size\n",
    "\n",
    "# parameter size computed from the previous image sizes and pooling layers\n",
    "cnn1.add(tf.keras.layers.Flatten())\n",
    "\n",
    "cnn1.add(tf.keras.layers.Dense(units=256, name='fc_1', activation='relu'))\n",
    "\n",
    "cnn1.add(tf.keras.layers.Dense(units=10, name='fc_2', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e307d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for repeatibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Build the model\n",
    "cnn1.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "# Compile the model with the optimizer, loss function and metric\n",
    "cnn1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "NUM_EPOCHS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78235b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights for debugging purposes and saving the model\n",
    "cnn1.save_weights('cnn1_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f14137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "439/439 [==============================] - 212s 477ms/step - loss: 0.9488 - accuracy: 0.6355\n",
      "Epoch 2/7\n",
      "439/439 [==============================] - 273s 621ms/step - loss: 0.6307 - accuracy: 0.7701\n",
      "Epoch 3/7\n",
      "439/439 [==============================] - 259s 590ms/step - loss: 0.4206 - accuracy: 0.8497\n",
      "Epoch 4/7\n",
      "439/439 [==============================] - 239s 545ms/step - loss: 0.2432 - accuracy: 0.9158\n",
      "Epoch 5/7\n",
      "439/439 [==============================] - 232s 529ms/step - loss: 0.1407 - accuracy: 0.9531\n",
      "Epoch 6/7\n",
      "439/439 [==============================] - 217s 493ms/step - loss: 0.0818 - accuracy: 0.9744\n",
      "Epoch 7/7\n",
      "439/439 [==============================] - 211s 480ms/step - loss: 0.0677 - accuracy: 0.9813\n",
      "CPU times: total: 1h 3min 21s\n",
      "Wall time: 28min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cnn1.fit(X_trscaled, y_tr,\n",
    "                   epochs=NUM_EPOCHS,\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef2a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 14s 139ms/step\n",
      "Accuracy= 0.728\n"
     ]
    }
   ],
   "source": [
    "# Testing dataset\n",
    "y_pred = np.argmax(cnn1.predict(X_tsscaled), axis=1)\n",
    "print(f'Accuracy= {sum(y_pred==y_ts)/len(X_ts):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a99f5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ddfe283",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# Our full CNN neural network\n",
    "cnn2 = tf.keras.Sequential()\n",
    "\n",
    "# if necessary keep the image size same padding='same'\n",
    "cnn2.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5),\n",
    "    data_format='channels_last',\n",
    "    name='conv_1', activation='relu'))\n",
    "\n",
    "cnn2.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_1'))  # 12x12 image size\n",
    "\n",
    "# if necessary keep the image size same padding='same'\n",
    "cnn2.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5),\n",
    "    name='conv_2', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)))\n",
    "\n",
    "cnn2.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_2'))  # 4x4 image size\n",
    "\n",
    "# parameter size computed from the previous image sizes and pooling layers\n",
    "cnn2.add(tf.keras.layers.Flatten())\n",
    "\n",
    "cnn2.add(tf.keras.layers.Dense(units=256, name='fc_1', activation='relu'))\n",
    "\n",
    "cnn2.add(tf.keras.layers.Dense(units=10, name='fc_2', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16e4dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for repeatibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Build the model\n",
    "cnn2.build(input_shape=(None, 128, 128, 3))\n",
    "\n",
    "# Compile the model with the optimizer, loss function and metric\n",
    "cnn2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f2dcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights for debugging purposes and saving the model\n",
    "cnn2.save_weights('cnn2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f770c856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "439/439 [==============================] - 273s 616ms/step - loss: 1.3305 - accuracy: 0.6156\n",
      "Epoch 2/10\n",
      "439/439 [==============================] - 253s 575ms/step - loss: 0.8662 - accuracy: 0.7096\n",
      "Epoch 3/10\n",
      "439/439 [==============================] - 254s 579ms/step - loss: 0.7168 - accuracy: 0.7626\n",
      "Epoch 4/10\n",
      "439/439 [==============================] - 257s 585ms/step - loss: 0.6319 - accuracy: 0.7956\n",
      "Epoch 5/10\n",
      "439/439 [==============================] - 254s 578ms/step - loss: 0.5354 - accuracy: 0.8293\n",
      "Epoch 6/10\n",
      "439/439 [==============================] - 256s 583ms/step - loss: 0.4578 - accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "439/439 [==============================] - 258s 587ms/step - loss: 0.3853 - accuracy: 0.8873\n",
      "Epoch 8/10\n",
      "439/439 [==============================] - 240s 547ms/step - loss: 0.3056 - accuracy: 0.9181\n",
      "Epoch 9/10\n",
      "439/439 [==============================] - 239s 545ms/step - loss: 0.2499 - accuracy: 0.9382\n",
      "Epoch 10/10\n",
      "439/439 [==============================] - 248s 565ms/step - loss: 0.2174 - accuracy: 0.9500\n",
      "CPU times: total: 1h 38min 52s\n",
      "Wall time: 43min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = cnn2.fit(X_trscaled, y_tr,\n",
    "                   epochs=NUM_EPOCHS,\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1d32a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 15s 155ms/step\n",
      "Accuracy= 0.732\n"
     ]
    }
   ],
   "source": [
    "# Testing dataset\n",
    "y_pred = np.argmax(cnn2.predict(X_tsscaled), axis=1)\n",
    "print(f'Accuracy= {sum(y_pred==y_ts)/len(X_ts):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510c6b5",
   "metadata": {},
   "source": [
    "q4:\n",
    "A model that overfits the data will have higher standard deviation on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
